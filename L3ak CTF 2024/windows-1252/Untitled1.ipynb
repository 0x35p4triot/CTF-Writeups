{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a21b7e49-c230-4a53-b74a-316b9c8827ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import from_pretrained_keras\n",
    "from skimage.io import imread\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b97533f4-0e34-4723-b46b-a15472dafd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "944e7ab0-db57-4135-a776-93c77b87c615",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = imread('test.png', as_gray=True)\n",
    "image = np.round((image * 255))\n",
    "image[image < 20] = 255\n",
    "image2 = 255 - image\n",
    "image2 = image2 / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab575015-d723-4463-8016-2910a01fbd10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ad5c9924d0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image2, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "13d1ae18-b5df-4abc-b15f-bcda83c60981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 25, 25)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I = image2[:25, :25]\n",
    "I = np.array([I, I, I])\n",
    "I.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "14c5ec64-7dc5-442b-9dbf-24df9929ca10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for C:\\Users\\spider\\.keras-ocr\\craft_mlt_25k.h5\n",
      "Looking for C:\\Users\\spider\\.keras-ocr\\crnn_kurapan.h5\n"
     ]
    }
   ],
   "source": [
    "pipeline = keras_ocr.pipeline.Pipeline()\n",
    "I = I / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1e26514f-bfeb-47ad-a9bf-3d4aa6242035",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (50,50) (3,) (50,50) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mI\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Tools\\Scoop\\apps\\python311\\current\\Lib\\site-packages\\keras_ocr\\pipeline.py:62\u001b[0m, in \u001b[0;36mPipeline.recognize\u001b[1;34m(self, images, detection_kwargs, recognition_kwargs)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recognition_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     recognition_kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m---> 62\u001b[0m box_groups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdetection_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m prediction_groups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecognizer\u001b[38;5;241m.\u001b[39mrecognize_from_boxes(\n\u001b[0;32m     64\u001b[0m     images\u001b[38;5;241m=\u001b[39mimages, box_groups\u001b[38;5;241m=\u001b[39mbox_groups, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrecognition_kwargs\n\u001b[0;32m     65\u001b[0m )\n\u001b[0;32m     66\u001b[0m box_groups \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     67\u001b[0m     tools\u001b[38;5;241m.\u001b[39madjust_boxes(boxes\u001b[38;5;241m=\u001b[39mboxes, boxes_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboxes\u001b[39m\u001b[38;5;124m\"\u001b[39m, scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m scale)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m scale \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m boxes\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m boxes, scale \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(box_groups, scales)\n\u001b[0;32m     71\u001b[0m ]\n",
      "File \u001b[1;32mD:\\Tools\\Scoop\\apps\\python311\\current\\Lib\\site-packages\\keras_ocr\\detection.py:777\u001b[0m, in \u001b[0;36mDetector.detect\u001b[1;34m(self, images, detection_threshold, text_threshold, link_threshold, size_threshold, **kwargs)\u001b[0m\n\u001b[0;32m    745\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdetect\u001b[39m(\n\u001b[0;32m    746\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    747\u001b[0m     images: typing\u001b[38;5;241m.\u001b[39mList[typing\u001b[38;5;241m.\u001b[39mUnion[np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mstr\u001b[39m]],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    752\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    753\u001b[0m ):\n\u001b[0;32m    754\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Recognize the text in a set of images.\u001b[39;00m\n\u001b[0;32m    755\u001b[0m \n\u001b[0;32m    756\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    775\u001b[0m \u001b[38;5;124;03m        size_threshold: The minimum area for a word.\u001b[39;00m\n\u001b[0;32m    776\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 777\u001b[0m     images \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mcompute_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    778\u001b[0m     boxes \u001b[38;5;241m=\u001b[39m getBoxes(\n\u001b[0;32m    779\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpredict(np\u001b[38;5;241m.\u001b[39marray(images), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs),\n\u001b[0;32m    780\u001b[0m         detection_threshold\u001b[38;5;241m=\u001b[39mdetection_threshold,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    783\u001b[0m         size_threshold\u001b[38;5;241m=\u001b[39msize_threshold,\n\u001b[0;32m    784\u001b[0m     )\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m boxes\n",
      "File \u001b[1;32mD:\\Tools\\Scoop\\apps\\python311\\current\\Lib\\site-packages\\keras_ocr\\detection.py:777\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    745\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdetect\u001b[39m(\n\u001b[0;32m    746\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    747\u001b[0m     images: typing\u001b[38;5;241m.\u001b[39mList[typing\u001b[38;5;241m.\u001b[39mUnion[np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mstr\u001b[39m]],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    752\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    753\u001b[0m ):\n\u001b[0;32m    754\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Recognize the text in a set of images.\u001b[39;00m\n\u001b[0;32m    755\u001b[0m \n\u001b[0;32m    756\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    775\u001b[0m \u001b[38;5;124;03m        size_threshold: The minimum area for a word.\u001b[39;00m\n\u001b[0;32m    776\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 777\u001b[0m     images \u001b[38;5;241m=\u001b[39m [\u001b[43mcompute_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images]\n\u001b[0;32m    778\u001b[0m     boxes \u001b[38;5;241m=\u001b[39m getBoxes(\n\u001b[0;32m    779\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpredict(np\u001b[38;5;241m.\u001b[39marray(images), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs),\n\u001b[0;32m    780\u001b[0m         detection_threshold\u001b[38;5;241m=\u001b[39mdetection_threshold,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    783\u001b[0m         size_threshold\u001b[38;5;241m=\u001b[39msize_threshold,\n\u001b[0;32m    784\u001b[0m     )\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m boxes\n",
      "File \u001b[1;32mD:\\Tools\\Scoop\\apps\\python311\\current\\Lib\\site-packages\\keras_ocr\\detection.py:40\u001b[0m, in \u001b[0;36mcompute_input\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m     37\u001b[0m mean \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0.485\u001b[39m, \u001b[38;5;241m0.456\u001b[39m, \u001b[38;5;241m0.406\u001b[39m])\n\u001b[0;32m     38\u001b[0m variance \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0.229\u001b[39m, \u001b[38;5;241m0.224\u001b[39m, \u001b[38;5;241m0.225\u001b[39m])\n\u001b[1;32m---> 40\u001b[0m \u001b[43mimage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m255\u001b[39;49m\n\u001b[0;32m     41\u001b[0m image \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m variance \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m255\u001b[39m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m image\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (50,50) (3,) (50,50) "
     ]
    }
   ],
   "source": [
    "predictions = pipeline.recognize(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5be7f5c-a5f9-4a58-b0aa-240e3827beb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
